---
# Determines which item appears first on the schedule (lowest number (0) appears first)
sequence_id: 5

day: Tuesday, 11th

# Time of the event
time: 13:30 - 14:15

# Title of the event
title: "Spotlight Talk II: Self-Tuning Track Winner"
subtitle: Schedules & Schedule-Free Learning

# Abstract
abstract: >
    I will introduce an alternative view of learning rate schedules, where they are considered as a technique for ensuring optimal convergence rates for the last iterate of an optimization procedure. This view leads to highly predictive theory of optimal learning rate schedules, explaining learning rate warmup and annealing procedures used in practice. Going beyond this, I will show how this viewpoint suggests Schedule-Free approaches, where learning rate schedules are replaced by iterate averaging schemes, which yield a number of benefits: no need to specify the stopping time in advance, smoother loss curves and often better eval metrics. This approach is ideally suited to the AlgoPerf competition's time-to-target setup.

# Speaker Info
speaker: Aaron Defazio
webpage: https://ai.meta.com/people/1115638629589333/aaron-defazio/
affil: Meta AI
affil_link: https://ai.meta.com/people/1115638629589333/aaron-defazio/
# affil2: Buzz University
# affil2_link: https://buzz.edu

# Image
img: ../other/aaron.jpg
img_link: https://ai.meta.com/people/1115638629589333/aaron-defazio/
---